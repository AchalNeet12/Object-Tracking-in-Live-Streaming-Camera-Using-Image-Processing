# Object Tracking in Live Streaming Camera Using Image Processing
---
## Description:
 - The project focuses on real-time object tracking using image processing techniques. The goal is to detect and track moving objects in a live camera feed, primarily using background 
   subtraction and contour detection for object detection, and a Euclidean distance tracker for maintaining object identities across frames. This can be applied to various domains like 
   traffic monitoring, surveillance systems, and automatic vehicle tracking.
---
## Overview:
- This project aims to build an intelligent system capable of detecting and tracking moving objects (such as vehicles) in a live camera feed. The system leverages computer vision 
  techniques to separate objects of interest from the background, processes the video frame by frame, and uses tracking algorithms to maintain the identity of the detected objects. The 
  key steps in the pipeline are:
   - Background Subtraction: Detect the difference between the current frame and a static background.
   - Contour Detection: Find contours of detected objects to define their boundaries.
   - Object Tracking: Track detected objects across frames using a Euclidean distance tracker, assigning unique IDs to each object.
     
- The application can be extended to use real-time video from various camera sources and can be utilized for monitoring vehicle movements in traffic or tracking objects in surveillance footage.
---
## Dataset:
- While the project does not rely on a pre-labeled dataset, it uses a live streaming video as input. For testing purposes, a sample video like "highway.mp4" can be used, which consists 
  of moving vehicles that serve as the primary objects of interest.
  - Dataset type: Real-time video or recorded footage
  - Data format: .mp4 or .avi video files (e.g., highway scenes with vehicles).
  - Data size: Varies based on video length and resolution.
    
- Since the project works with live video streams, any video feed containing moving objects can be considered as a dataset.
---
## Technologies Used:
- Programming Language: `Python`
- Libraries:
  - `OpenCV`: For image processing, background subtraction, contour detection, and drawing bounding boxes.
  - `NumPy`: For numerical operations and matrix manipulation.
  - `EuclideanDistTracker`: For object tracking (custom or pre-built tracker).
  - `Video Input`: Live camera feed or pre-recorded video (e.g., .mp4).
    
- These technologies allow the program to process video streams in real-time and use efficient image processing algorithms for object detection and tracking.
---
## Data Preprocessing:
 - **Frame Extraction**: Each frame of the video stream is extracted for processing.
 - **Region of Interest (ROI)**: A specific region in the frame (like the road) is selected for processing, reducing unnecessary computational overhead.
 - **Background Subtraction**: The background of the frame is subtracted to detect moving objects by distinguishing them from the static background.
 - **Thresholding**: The mask generated by background subtraction is thresholded to create binary images (black and white) where objects are white and the background is black.
 - **Morphological Operations**: These operations (like dilation and erosion) clean up the mask to remove noise and small irrelevant objects.
 - **Contour Detection**: The contours of detected objects are identified and used to define the bounding boxes of the objects.
 - **Tracking**: Using a tracking algorithm, the positions of the detected objects are tracked across consecutive frames.
---
## Results:
The system is capable of accurately detecting and tracking objects (e.g., vehicles) in a live streaming camera feed. The results include:
 - **Detection**: Objects in the region of interest are successfully detected as they move across the video frames.
 - **Tracking**: Each detected object is assigned a unique ID and tracked across multiple frames.
 - **Visualization**: Bounding boxes are drawn around detected objects, and their unique IDs are displayed on the frame, showing real-time tracking.
   
- In case of vehicles, the system successfully tracks each vehicle through the scene, even if they move in different directions.
---
## Conclusion:
The project demonstrates an effective approach to real-time object tracking in live camera streams using image processing techniques. The use of background subtraction for detection, contour analysis, and a simple tracking algorithm offers a reliable solution for tracking moving objects, such as vehicles, in dynamic environments. This approach has wide applications in traffic monitoring, surveillance, and other fields requiring real-time object detection and tracking.

  - **Strengths**: The system is capable of working in real-time, making it suitable for live traffic monitoring or surveillance applications.
  - **Limitations**: The current system relies on simple background subtraction and contour detection, which might not be robust in cases with complex backgrounds or rapid movements. 
      Further improvements could involve incorporating more advanced machine learning or deep learning models (e.g., YOLO or DeepSORT) to handle more complex scenes.
  - **Future Work**: To improve the accuracy and robustness of the tracking system, it could be extended by incorporating deep learning models for object detection, especially for 
      handling challenging scenarios like occlusions, varying lighting conditions, and fast-moving objects.
    
- This project provides a foundational framework for live object tracking and can be extended with more sophisticated methods to handle various complex tracking scenarios.







